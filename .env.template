# ==============================================================================
# ||        LLM API Key Proxy - Ready to Use Template                        ||
# ==============================================================================
#
# INSTRUCTIONS:
# 1. Copy this file to .env
# 2. Replace all placeholder values with your real API keys
# 3. Only keep the providers you actually have keys for
# 4. The PROXY_API_KEY can be any strong password you create
#

# ------------------------------------------------------------------------------
# | [REQUIRED] Proxy Server Authentication                                    |
# ------------------------------------------------------------------------------

# Create any strong password for your proxy (this authenticates requests to YOUR proxy)
PROXY_API_KEY="change-this-to-a-strong-password-12345"

# ------------------------------------------------------------------------------
# | [RECOMMENDED] Start with These Free Providers                             |
# ------------------------------------------------------------------------------

# Groq - Very fast, generous free tier (RECOMMENDED TO START WITH)
# Get your key at: https://console.groq.com
GROQ_API_KEY_1=""

# OpenRouter - Access to many models including free ones
# Get your key at: https://openrouter.ai
OPENROUTER_API_KEY_1=""

# Google Gemini - Good free tier
# Get your key at: https://makersuite.google.com/app/apikey
GEMINI_API_KEY_1=""

# ------------------------------------------------------------------------------
# | [OPTIONAL] Paid Providers (Better Performance)                            |
# ------------------------------------------------------------------------------

# OpenAI - Most popular, excellent models
# Get your key at: https://platform.openai.com
OPENAI_API_KEY_1=""

# Anthropic - Claude models, very good for coding
# Get your key at: https://console.anthropic.com
ANTHROPIC_API_KEY_1=""

# ------------------------------------------------------------------------------
# | [ADVANCED] G4F Fallback Providers                                        |
# ------------------------------------------------------------------------------
# G4F provides access to free LLM providers as fallbacks
# Only configure these if you have G4F proxy endpoints
G4F_API_KEY=""
G4F_MAIN_API_BASE=""
G4F_GROQ_API_BASE=""
G4F_GEMINI_API_BASE=""

# ------------------------------------------------------------------------------
# | [OPTIONAL] Advanced Settings                                             |
# ------------------------------------------------------------------------------

# Model preferences (leave empty to use all available models)
IGNORE_MODELS_GEMINI=""
IGNORE_MODELS_OPENAI=""
WHITELIST_MODELS_GEMINI=""
WHITELIST_MODELS_OPENAI=""

# Performance settings (good defaults)
MAX_CONCURRENT_REQUESTS_PER_KEY_OPENAI=3
MAX_CONCURRENT_REQUESTS_PER_KEY_GEMINI=1
MAX_CONCURRENT_REQUESTS_PER_KEY_GROQ=5

# Rotation mode (balanced = distribute load, sequential = use until exhausted)
ROTATION_MODE_GROQ=balanced
ROTATION_MODE_OPENAI=balanced