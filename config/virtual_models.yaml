virtual_models:
  coding-smart:
    description: "Best models for complex coding tasks, prioritizing quality"
    fallback_chain:
      - provider: gemini
        model: gemini-1.5-pro
        priority: 1
        conditions:
          max_daily_requests: 50
      - provider: groq
        model: llama-3.3-70b-versatile
        priority: 2
      - provider: g4f
        model: gpt-4
        priority: 3
    settings:
      timeout_ms: 120000
      retry_on_rate_limit: true

  coding-fast:
    description: "Fast models for simple coding tasks"
    fallback_chain:
      - provider: groq
        model: llama-3.1-8b-instant
        priority: 1
      - provider: gemini
        model: gemini-1.5-flash
        priority: 2
      - provider: g4f
        model: gpt-3.5-turbo
        priority: 3
    settings:
      timeout_ms: 30000

  chat-smart:
    description: "Best models for complex reasoning/chat"
    fallback_chain:
      - provider: gemini
        model: gemini-1.5-pro
        priority: 1
      - provider: groq
        model: llama-3.3-70b-versatile
        priority: 2
    settings:
      timeout_ms: 60000

  chat-fast:
    description: "Fast models for simple chat"
    fallback_chain:
      - provider: groq
        model: llama-3.1-8b-instant
        priority: 1
      - provider: gemini
        model: gemini-1.5-flash
        priority: 2
    settings:
      timeout_ms: 30000

providers:
  gemini:
    base_url: "https://generativelanguage.googleapis.com/v1beta"
    api_key_env: "GEMINI_API_KEY"
    rate_limits:
      rpm: 15
      daily: 1500

  groq:
    base_url: "https://api.groq.com/openai/v1"
    api_key_env: "GROQ_API_KEY"
    rate_limits:
      rpm: 30
      daily: 14400

  g4f:
    base_url: "https://g4f.dev/v1"
    api_key_env: "G4F_API_KEY"
    rate_limits:
      rpm: 10
      daily: 100
