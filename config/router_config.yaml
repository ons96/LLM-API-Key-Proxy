free_only_mode: true
proxy_api_keys:
- ${PROXY_API_KEY}
providers:
  groq:
    enabled: true
    env_var: GROQ_API_KEY
    free_tier_models:
    # Core models (existing)
    - llama-3.1-8b-instant
    - llama-3.3-70b-versatile
    - mixtral-8x7b-32768
    - gemma2-9b-it
    # Llama 4 models (NEW - discovered from API)
    - meta-llama/llama-4-maverick-17b-128e-instruct
    - meta-llama/llama-4-scout-17b-16e-instruct
    # Compound models (NEW)
    - groq/compound
    - groq/compound-mini
    # Kimi models (NEW - large context window)
    - moonshotai/kimi-k2-instruct
    - moonshotai/kimi-k2-instruct-0905
    # OpenAI OSS models (NEW - coding focused)
    - openai/gpt-oss-120b
    - openai/gpt-oss-20b
    # Qwen models (NEW - excellent for coding)
    - qwen/qwen3-32b
    # Arabic models
    - allam-2-7b
    - canopylabs/orpheus-arabic-saudi
    - canopylabs/orpheus-v1-english
  g4f:
    enabled: true
  gemini:
    enabled: true
    env_var: GEMINI_API_KEY
    free_tier_models:
    - gemini-2.5-flash
    - gemini-2.5-pro
    - gemini-2.0-flash
    - gemini-3-pro-preview
    - gemma-3-27b-it
    - gemini-1.5-flash
    - gemini-1.5-pro
  cerebras:
    enabled: true
    env_var: CEREBRAS_API_KEY
    free_tier_models:
    # Llama models (existing)
    - llama-3.3-70b
    - llama3.1-8b
    # Qwen models (NEW - EXCELLENT for coding!)
    - qwen-3-235b-a22b-instruct-2507  # 235B parameter model - best for complex coding
    - qwen-3-32b  # Fast and capable
    # Other models (NEW)
    - gpt-oss-120b  # Large open-source model
    - zai-glm-4.7  # Chinese language model
  openai:
    enabled: true
    env_var: OPENAI_API_KEY
    free_tier_models:
    - gpt-4o-mini
    - gpt-3.5-turbo
  nvidia:
    enabled: true
    env_var: NVIDIA_API_KEY
    free_tier_models:
    - nvidia/llama-3.3-70b-instruct
    - nvidia/llama-3.1-405b-instruct
    - nvidia/gemma-2-27b-it
  mistral:
    enabled: true
    env_var: MISTRAL_API_KEY
    free_tier_models:
    - mistral-large-latest
    - codestral-latest
    - mistral-nemo
  openrouter:
    enabled: true
    env_var: OPENROUTER_API_KEY
    free_tier_models:
    - meta-llama/llama-3.3-70b-instruct
    - deepseek/deepseek-chat
    - google/gemini-flash-1.5
  sambanova:
    enabled: false
    env_var: SAMBANOVA_API_KEY
    free_tier_models:
    - DeepSeek-V3.2
    - DeepSeek-R1-Distill-Llama-70B
    - Llama-4-Maverick-17B-128E-Instruct
    - Meta-Llama-3.1-8B-Instruct
    - Meta-Llama-3.3-70B-Instruct
    - Qwen3-235B
    - Qwen3-32B
    - gpt-oss-120b
  together:
    enabled: true
    env_var: TOGETHER_API_KEY
    free_tier_models:
    - togethercomputer/MoA-1
    - togethercomputer/MoA-1-Turbo
    - meta-llama/Llama-3.3-70B-Instruct-Turbo
    - deepseek-ai/DeepSeek-V3
  github-models:
    enabled: false
    env_var: GITHUB_MODELS_API_KEY
    free_tier_models:
    - grok-3-vision-beta
    - grok-3-mini
    - deepseek-r1
    - deepseek-v3
    - phi-4
    - llama-4-scout-17b
    - meta-llama/Llama-3.3-70B-Instruct
    - mistralai/Mistral-large-2411
  cloudflare:
    enabled: false
    env_var: CLOUDFLARE_API_TOKEN
    free_tier_models:
    - "@cf/meta/llama-3.3-70b-instruct"
    - "@cf/meta/llama-3.1-8b-instruct"
    - "@cf/mistral/mistral-large-2407"
    - "@cf/qwen/qwen2.5-72b-instruct"
    - "@cf/openchat/openchat-7b"
    - "@cf/tinyllama/tinyllama-1.1b-chat"
    api_base: "https://api.cloudflare.com/client/v4/accounts/{CLOUDFLARE_ACCOUNT_ID}/ai/run/"
  brave_search:
    enabled: true
    env_var: BRAVE_API_KEY
    free_tier: true
  tavily:
    enabled: true
    env_var: TAVILY_API_KEY
    free_tier: true
    paid_tier: true
  duckduckgo:
    enabled: true
    free_tier: true
    no_api_key_required: true
  exa:
    enabled: false
    env_var: EXA_API_KEY
    free_tier: false
    paid_tier: true
  router_models:
  router/best-coding:
    description: Best for coding tasks
    candidates:
    - provider: groq
      model: llama-3.3-70b-versatile
      priority: 1
      capabilities:
      - tools
      - function_calling
    - provider: gemini
      model: gemini-3-pro
      priority: 2
      capabilities:
      - tools
      - function_calling
      fallback_only: true
    - provider: g4f
      model: gpt-4
      priority: 3
      fallback_only: true
  router/best-reasoning:
    description: Best for reasoning and analysis
    candidates:
    - provider: groq
      model: llama-3.3-70b-versatile
      priority: 1
      capabilities:
      - reasoning
    - provider: gemini
      model: gemini-3-pro
      priority: 2
      capabilities:
      - reasoning
      - long_context
      fallback_only: true
  router/best-research:
    description: Best for research with search capabilities
    candidates:
    - provider: gemini
      model: gemini-3-pro
      priority: 1
      capabilities:
      - tools
      - long_context
      search_enabled: true
    - provider: groq
      model: llama-3.3-70b-versatile
      priority: 2
      capabilities:
      - tools
      search_enabled: true
      fallback_only: true
  router/best-chat:
    description: Best for general chat
    candidates:
    - provider: groq
      model: llama-3.1-8b-instant
      priority: 1
      capabilities:
      - fast
    - provider: gemini
      model: gemini-2-5-flash
      priority: 2
      capabilities:
      - fast
      fallback_only: true
    - provider: g4f
      model: gpt-3.5-turbo
      priority: 3
      fallback_only: true
  router/best-coding-moe:
    description: Committee/MoE mode for coding
    moe_mode: true
    max_experts: 3
    aggregator_model: groq/llama-3.3-70b-versatile
    candidates:
    - provider: groq
      model: llama-3.3-70b-versatile
      role: expert-architect
    - provider: gemini
      model: gemini-3-pro
      role: expert-secure-coding
    - provider: groq
      model: mixtral-8x7b-32768
      role: expert-optimization
      fallback_only: true
  coding-smart:
    description: Best models for complex coding tasks (Free tier)
    candidates:
    - provider: groq
      model: llama-3.3-70b-versatile
      priority: 1
      capabilities:
      - tools
      - function_calling
      - reasoning
    - provider: gemini
      model: gemini-1.5-pro
      priority: 2
      fallback_only: true
    - provider: g4f
      model: gpt-4
      priority: 3
      fallback_only: true
  coding-fast:
    description: Fastest models for quick coding tasks (Free tier)
    candidates:
    - provider: groq
      model: llama-3.1-8b-instant
      priority: 1
      capabilities:
      - tools
      - function_calling
      - fast
    - provider: gemini
      model: gemini-2-5-flash
      priority: 2
      fallback_only: true
    - provider: g4f
      model: gpt-4
      priority: 3
      fallback_only: true
  chat-smart:
    description: High intelligence chat models (Free tier)
    candidates:
    - provider: groq
      model: llama-3.3-70b-versatile
      priority: 1
      capabilities:
      - tools
      - function_calling
      - reasoning
    - provider: gemini
      model: gemini-1.5-pro
      priority: 2
      fallback_only: true
    - provider: g4f
      model: gpt-4
      priority: 3
      fallback_only: true
  chat-fast:
    description: Low latency chat models (Free tier)
    candidates:
    - provider: groq
      model: llama-3.1-8b-instant
      priority: 1
      capabilities:
      - fast
      - tools
    - provider: gemini
      model: gemini-2-5-flash
      priority: 2
      fallback_only: true
    - provider: g4f
      model: gpt-3.5-turbo
      priority: 3
      fallback_only: true
search:
  default_enabled: true
  max_additional_searches: 2
  intelligent_tiers: true
  providers:
  - name: tavily
    enabled: true
    priority: 1
    free_only: true
    paid_available: true
    supports_tiers:
    - basic
    - advanced
    - research_mini
    - research_pro
  - name: brave
    enabled: true
    priority: 2
    free_only: true
  - name: duckduckgo
    enabled: true
    priority: 3
    free_only: true
    no_api_key_required: true
  - name: exa
    enabled: false
    priority: 4
    free_only: false
    paid_only: true
routing:
  default_cooldown_seconds: 60
  rate_limit_cooldown_seconds: 300
  max_consecutive_failures: 3
  ewma_alpha: 0.3
  latency_window_minutes: 15
  default_timeout_seconds: 30
  max_timeout_seconds: 120
  max_retries_per_candidate: 2
  retry_on_transient_errors: true
capabilities:
  needs_tools:
  - tools
  - function_calling
  needs_vision:
  - vision
  needs_structured_output:
  - json_mode
  - structured_output
  needs_long_context:
  - long_context
  - 32k_context
  - 128k_context
logging:
  level: INFO
  log_requests: true
  log_candidates: true
  log_search_decisions: true
  safe_fields:
  - model
  - provider
  - request_id
  - latency
safety:
  max_tokens_per_request: 400000
  max_moe_tokens_multiplier: 2.5
  forbidden_providers_under_free_mode:
  - openai
  - anthropic
  - cohere
